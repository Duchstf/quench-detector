{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ramp 21 -- Variances and mean of abs(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/uscms_data/d3/dhoang/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Data processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nptdms import TdmsFile #Process ramping file\n",
    "\n",
    "#For building ML models\n",
    "import keras\n",
    "import keras.models as models\n",
    "from keras.layers.core import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_and_time(dir_path, channel):\n",
    "    data_frame = pd.DataFrame(data = {channel: np.load(dir_path + channel + \".npy\"),\n",
    "                                     \"time\": np.load(dir_path + \"time.npy\")})\n",
    "    return data_frame\n",
    "    \n",
    "def generate_data_0(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    #data[\"Mean\"] = data.loc[:, channel].abs().rolling(window=window).mean()\n",
    "    data[\"SD\"] = data.loc[:, channel].rolling(window=window).std()\n",
    "    #data[\"Kurtosis\"] = data.loc[:, channel].rolling(window=window).kurt()\n",
    "    #data[\"Skew\"] = data.loc[:, channel].rolling(window=window).skew()\n",
    "    \n",
    "    select_list = [\"SD\"]\n",
    "    \n",
    "    assert data[select_list].to_numpy()[window-1::step].shape[0] == data['time'].to_numpy()[window-1::step].shape[0]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return data[select_list].to_numpy()[window-1::step], data['time'].to_numpy()[window-1::step]\n",
    "\n",
    "def generate_data_no_time(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    #data[\"Mean\"] = data.loc[:, channel].abs().rolling(window=window).mean()\n",
    "    data[\"SD\"] = data.loc[:, channel].rolling(window=window).std()\n",
    "    #data[\"Kurtosis\"] = data.loc[:, channel].rolling(window=window).kurt()\n",
    "    #data[\"Skew\"] = data.loc[:, channel].rolling(window=window).skew()\n",
    "    \n",
    "    select_list = [\"SD\"]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return data[select_list].to_numpy()[window-1::step]\n",
    "\n",
    "def generate_data_all_sensors(dir_path, time_range, window = 1000, step = 10):\n",
    "    \n",
    "    ai0, time = generate_data(dir_path, \"ai0\", time_range = time_range, window = window, step = step)\n",
    "    ai1 = generate_data_no_time(dir_path, \"ai1\", time_range = time_range, window = window, step = step)\n",
    "    ai2 = generate_data_no_time(dir_path, \"ai2\", time_range = time_range, window = window, step = step)\n",
    "    ai3 = generate_data_no_time(dir_path, \"ai3\", time_range = time_range, window = window, step = step)\n",
    "    ai4 = generate_data_no_time(dir_path, \"ai4\", time_range = time_range, window = window, step = step)\n",
    "    \n",
    "    #Multiply them all together\n",
    "    product_var = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    \n",
    "    all_channels = np.concatenate((ai0,ai1,ai2,ai3,ai4,product_var), axis = 1)\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_channels, time\n",
    "\n",
    "def plot_moving_mean(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the mean\n",
    "    data[\"Mean\"] = data.loc[:, channel].abs().rolling(window=window).mean()\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(data['time'].to_numpy()[window-1::step], data[\"Mean\"].to_numpy()[window-1::step], label = \"Mean of abs(data)\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Sensor {}'s moving mean\".format(channel))\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "def load_sensor(dir_path, sensor, time_range = None):\n",
    "    \n",
    "    data = pd.DataFrame(data = {sensor: np.load(dir_path + sensor + \".npy\"),\n",
    "                                \"time\": np.load(dir_path + \"time.npy\")})\n",
    "    \n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "    \n",
    "    \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "   \n",
    "    %reset -f in\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def plot_product_mean(dir_path, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    \n",
    "    time_axis = ai0['time'].to_numpy()[window-1::step]\n",
    "    \n",
    "    ai0 = ai0[\"ai0\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    \n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(time_axis, product)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Product of moving means\")\n",
    "    \n",
    "def plot_SD(dir_path, channel, time_range, window = 2000, step = 10):\n",
    "    \n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the mean\n",
    "    data[\"SD\"] = data.loc[:, channel].abs().rolling(window=window).std()\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(data['time'].to_numpy()[window-1::step], data[\"SD\"].to_numpy()[window-1::step], label = \"Standard deviation\", color = \"red\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Sensor {}'s moving standard deviation\".format(channel))\n",
    "    \n",
    "    %reset -f in\n",
    "\n",
    "\n",
    "def plot_product_SD(dir_path, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    \n",
    "    time_axis = ai0['time'].to_numpy()[window-1::step]\n",
    "    \n",
    "    ai0 = ai0[\"ai0\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    \n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(time_axis, product, color = \"red\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Product of moving standard deviations\")\n",
    "    \n",
    "def generate_mean_data(dir_path, time_range, window = 2000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)[\"ai0\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    \n",
    "    #Calculate the product\n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Stack them together\n",
    "    all_mean = np.vstack((ai0,ai1,ai2,ai3,ai4, product)).transpose()\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_mean\n",
    "\n",
    "def generate_sd_data(dir_path, time_range, window = 2000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)[\"ai0\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    \n",
    "    #Calculate the product\n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Stack them together\n",
    "    all_sd = np.vstack((ai0,ai1,ai2,ai3,ai4, product)).transpose()\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_sd\n",
    "\n",
    "def load_time_label(dir_path, time_range, window = 2000, step = 10):\n",
    "    \n",
    "    time_label =  np.load(dir_path + \"time.npy\")\n",
    "    \n",
    "    start = min(time_label)\n",
    "    end = max(time_label)\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "    \n",
    "    \n",
    "    time_label = time_label[(time_label > start) & (time_label < end)][window-1::step]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return time_label\n",
    "    \n",
    "\n",
    "def generate_data(dir_path, time_range, window = 2000, step = 10):\n",
    "    \n",
    "    moving_mean = generate_mean_data(dir_path, time_range, window = 2000, step = 10)\n",
    "    moving_sd = generate_sd_data(dir_path, time_range, window = 2000, step = 10)\n",
    "    time_label = load_time_label(dir_path, time_range, window = 2000, step = 10)\n",
    "    \n",
    "    all_data = np.concatenate((moving_mean, moving_sd), axis = 1)\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_data, time_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "X_train's shape:  (999800, 12)\n",
      "X_test's shape:  (499800, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, train_time = generate_data(\"./data/Ramp21/\", time_range = (-450, -350), window = 2000, step = 10)\n",
    "X_test, test_time = generate_data(\"./data/Ramp21/\", time_range = (-50, 0), window = 2000, step = 10)\n",
    "print(\"X_train's shape: \", X_train.shape)\n",
    "print(\"X_test's shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.3.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                84        \n",
      "=================================================================\n",
      "Total params: 207\n",
      "Trainable params: 207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#================BUILD THE MODEL====================\n",
    "print(\"Using Keras version: \", keras.__version__)\n",
    "\n",
    "# Simple model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'elu', kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(3,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899820 samples, validate on 99980 samples\n",
      "Epoch 1/50\n",
      "899820/899820 [==============================] - 6s 6us/step - loss: 4.6238e-04 - val_loss: 7.5318e-05\n",
      "Epoch 2/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1847e-04 - val_loss: 6.0783e-05\n",
      "Epoch 3/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 9.8719e-05 - val_loss: 5.6483e-05\n",
      "Epoch 4/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 8.9993e-05 - val_loss: 5.2300e-05\n",
      "Epoch 5/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 8.5756e-05 - val_loss: 5.0795e-05\n",
      "Epoch 6/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 8.2643e-05 - val_loss: 4.7131e-05\n",
      "Epoch 7/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 8.0342e-05 - val_loss: 4.4887e-05\n",
      "Epoch 8/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.8651e-05 - val_loss: 4.4547e-05\n",
      "Epoch 9/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.7494e-05 - val_loss: 4.0386e-05\n",
      "Epoch 10/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.6560e-05 - val_loss: 4.2343e-05\n",
      "Epoch 11/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.5998e-05 - val_loss: 4.2839e-05\n",
      "Epoch 12/50\n",
      "899820/899820 [==============================] - 6s 6us/step - loss: 7.5542e-05 - val_loss: 4.4795e-05\n",
      "Epoch 13/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.5162e-05 - val_loss: 4.5826e-05\n",
      "Epoch 14/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.4784e-05 - val_loss: 4.1621e-05\n",
      "Epoch 15/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.4406e-05 - val_loss: 3.9882e-05\n",
      "Epoch 16/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.3957e-05 - val_loss: 4.0770e-05\n",
      "Epoch 17/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.3526e-05 - val_loss: 4.1312e-05\n",
      "Epoch 18/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.3004e-05 - val_loss: 4.2634e-05\n",
      "Epoch 19/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.2357e-05 - val_loss: 4.1767e-05\n",
      "Epoch 20/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.1657e-05 - val_loss: 4.1938e-05\n",
      "Epoch 21/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.0741e-05 - val_loss: 4.2242e-05\n",
      "Epoch 22/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.9784e-05 - val_loss: 4.3522e-05\n",
      "Epoch 23/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.8754e-05 - val_loss: 4.0492e-05\n",
      "Epoch 24/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.7829e-05 - val_loss: 4.1527e-05\n",
      "Epoch 25/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.6838e-05 - val_loss: 4.1595e-05\n",
      "Epoch 26/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.6046e-05 - val_loss: 4.2392e-05\n",
      "Epoch 27/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.5282e-05 - val_loss: 4.0853e-05\n",
      "Epoch 28/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.4621e-05 - val_loss: 4.1208e-05\n",
      "Epoch 29/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.4154e-05 - val_loss: 4.1320e-05\n",
      "Epoch 30/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.3758e-05 - val_loss: 4.1729e-05\n",
      "Epoch 31/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.3422e-05 - val_loss: 4.1475e-05\n",
      "Epoch 32/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.3155e-05 - val_loss: 4.0299e-05\n",
      "Epoch 33/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2925e-05 - val_loss: 4.2542e-05\n",
      "Epoch 34/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2669e-05 - val_loss: 3.9950e-05\n",
      "Epoch 35/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2480e-05 - val_loss: 4.1382e-05\n",
      "Epoch 36/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2320e-05 - val_loss: 4.0806e-05\n",
      "Epoch 37/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2158e-05 - val_loss: 4.0887e-05\n",
      "Epoch 38/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1976e-05 - val_loss: 3.9386e-05\n",
      "Epoch 39/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1892e-05 - val_loss: 4.4902e-05\n",
      "Epoch 40/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1649e-05 - val_loss: 4.2477e-05\n",
      "Epoch 41/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1574e-05 - val_loss: 3.8916e-05\n",
      "Epoch 42/50\n",
      "899820/899820 [==============================] - 6s 6us/step - loss: 6.1435e-05 - val_loss: 3.9647e-05\n",
      "Epoch 43/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1287e-05 - val_loss: 4.0725e-05\n",
      "Epoch 44/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1188e-05 - val_loss: 4.1699e-05\n",
      "Epoch 45/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1066e-05 - val_loss: 3.8753e-05\n",
      "Epoch 46/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.0936e-05 - val_loss: 4.0004e-05\n",
      "Epoch 47/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.0880e-05 - val_loss: 3.9076e-05\n",
      "Epoch 48/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.0729e-05 - val_loss: 4.0629e-05\n",
      "Epoch 49/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.0703e-05 - val_loss: 3.8137e-05\n",
      "Epoch 50/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.0570e-05 - val_loss: 3.7080e-05\n"
     ]
    }
   ],
   "source": [
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=1028\n",
    "\n",
    "history=model.fit(X_train, X_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mse'] = np.mean(np.abs(X_pred-X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "scored_test = pd.DataFrame()\n",
    "scored_test['Loss_mse'] = np.mean(np.abs(X_pred_test-X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(train_time, scored['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(test_time, scored_test['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlim([-11.8,-11.6])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Try other ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (-250,-50)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "X_train's shape:  (999800, 12)\n",
      "X_test's shape:  (1999800, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, train_time = generate_data(\"./data/Ramp21/\", time_range = (-450, -350), window = 2000, step = 10)\n",
    "X_test, test_time = generate_data(\"./data/Ramp21/\", time_range = (-250, -50), window = 2000, step = 10)\n",
    "print(\"X_train's shape: \", X_train.shape)\n",
    "print(\"X_test's shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.3.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                84        \n",
      "=================================================================\n",
      "Total params: 207\n",
      "Trainable params: 207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#================BUILD THE MODEL====================\n",
    "print(\"Using Keras version: \", keras.__version__)\n",
    "\n",
    "# Simple model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'elu', kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(3,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899820 samples, validate on 99980 samples\n",
      "Epoch 1/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 3.6266e-04 - val_loss: 7.6136e-05\n",
      "Epoch 2/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.2108e-04 - val_loss: 6.6456e-05\n",
      "Epoch 3/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.0634e-04 - val_loss: 6.5474e-05\n",
      "Epoch 4/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.0308e-04 - val_loss: 6.5802e-05\n",
      "Epoch 5/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.0105e-04 - val_loss: 6.4016e-05\n",
      "Epoch 6/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 9.8942e-05 - val_loss: 6.4241e-05\n",
      "Epoch 7/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 9.7073e-05 - val_loss: 6.3354e-05\n",
      "Epoch 8/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 9.5863e-05 - val_loss: 6.1482e-05\n",
      "Epoch 9/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 9.5093e-05 - val_loss: 6.1410e-05\n",
      "Epoch 10/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 9.4127e-05 - val_loss: 5.9247e-05\n",
      "Epoch 11/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 9.2003e-05 - val_loss: 5.2288e-05\n",
      "Epoch 12/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 8.2701e-05 - val_loss: 4.2583e-05\n",
      "Epoch 13/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 7.2936e-05 - val_loss: 3.5947e-05\n",
      "Epoch 14/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.8476e-05 - val_loss: 3.4186e-05\n",
      "Epoch 15/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.5966e-05 - val_loss: 3.3639e-05\n",
      "Epoch 16/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.4151e-05 - val_loss: 3.3798e-05\n",
      "Epoch 17/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2932e-05 - val_loss: 3.1817e-05\n",
      "Epoch 18/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.2013e-05 - val_loss: 3.3772e-05\n",
      "Epoch 19/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.1292e-05 - val_loss: 3.2178e-05\n",
      "Epoch 20/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.0632e-05 - val_loss: 2.8990e-05\n",
      "Epoch 21/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.0102e-05 - val_loss: 3.1275e-05\n",
      "Epoch 22/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.9648e-05 - val_loss: 3.0951e-05\n",
      "Epoch 23/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.9186e-05 - val_loss: 3.1215e-05\n",
      "Epoch 24/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.8825e-05 - val_loss: 3.0929e-05\n",
      "Epoch 25/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.8527e-05 - val_loss: 2.8689e-05\n",
      "Epoch 26/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.8225e-05 - val_loss: 2.8437e-05\n",
      "Epoch 27/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.8013e-05 - val_loss: 3.0566e-05\n",
      "Epoch 28/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.7751e-05 - val_loss: 3.1294e-05\n",
      "Epoch 29/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.7589e-05 - val_loss: 2.9918e-05\n",
      "Epoch 30/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.7413e-05 - val_loss: 2.8660e-05\n",
      "Epoch 31/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.7179e-05 - val_loss: 2.9774e-05\n",
      "Epoch 32/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.7078e-05 - val_loss: 2.8399e-05\n",
      "Epoch 33/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.6921e-05 - val_loss: 3.1228e-05\n",
      "Epoch 34/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.6819e-05 - val_loss: 2.9516e-05\n",
      "Epoch 35/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 5.6677e-05 - val_loss: 2.7107e-05\n",
      "Epoch 36/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 5.6601e-05 - val_loss: 3.0805e-05\n",
      "Epoch 37/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.6524e-05 - val_loss: 2.8643e-05\n",
      "Epoch 38/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 5.6389e-05 - val_loss: 2.9080e-05\n",
      "Epoch 39/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.6332e-05 - val_loss: 2.8853e-05\n",
      "Epoch 40/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 5.6205e-05 - val_loss: 2.9715e-05\n",
      "Epoch 41/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.6121e-05 - val_loss: 2.8451e-05\n",
      "Epoch 42/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 5.6042e-05 - val_loss: 2.8156e-05\n",
      "Epoch 43/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.5990e-05 - val_loss: 3.1406e-05\n",
      "Epoch 44/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.5872e-05 - val_loss: 2.9248e-05\n",
      "Epoch 45/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.5828e-05 - val_loss: 2.7840e-05\n",
      "Epoch 46/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.5786e-05 - val_loss: 2.8766e-05\n",
      "Epoch 47/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.5752e-05 - val_loss: 3.2238e-05\n",
      "Epoch 48/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 5.5657e-05 - val_loss: 3.2131e-05\n",
      "Epoch 49/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 5.5591e-05 - val_loss: 2.8327e-05\n",
      "Epoch 50/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 5.5609e-05 - val_loss: 2.9762e-05\n"
     ]
    }
   ],
   "source": [
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=1028\n",
    "\n",
    "history=model.fit(X_train, X_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mse'] = np.mean(np.abs(X_pred-X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "scored_test = pd.DataFrame()\n",
    "scored_test['Loss_mse'] = np.mean(np.abs(X_pred_test-X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAACeCAYAAABD0NHYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAP3klEQVR4nO3df8xddX0H8PdHkLkhAmJhSNlArTASRbECjpmhOAdsEZdppiNCCAkxA9Q5J4jJZoZLMFlEzDYzgts0cWMGibCJPxBFNxmMovwQK9KxCRWQIgx/oDOVz/64p+NSnraXtrdP6Xm9kpvnfL/ne+/93qSf3vO8n+85p7o7AAAAAIzHUxZ7AgAAAABsWwIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGJmZAqGq2qOqLqmqb1bVyqp6WVU9s6qurKrbh597DmOrqj5YVauq6uaqOmy+HwEAAACAJ2LWFUIXJPlMdx+c5NAkK5OcneSq7l6W5KqhnSTHJVk2PE5L8qGtOmMAAAAAtkh198YHVD0jyU1JntNTg6vqtiRHd/c9VbVvkqu7+6Cq+pth+x/XHze3TwEAAADAzGZZIfScJGuS/F1Vfa2qLqqqXZPssy7kGX7uPYzfL8ldU89fPfQBAAAAsB3YecYxhyU5s7uvq6oL8ujpYQupBfoetwypqk7L5JSy7Lrrri85+OCDZ5gKAAAAALO44YYb7u/uJQvtmyUQWp1kdXdfN7QvySQQ+m5V7Tt1yth9U+P3n3r+0iR3r/+i3X1hkguTZPny5b1ixYqZPgwAAAAAm1ZV397Qvk2eMtbd9ya5q6oOGrqOSfKNJJcnOXnoOznJZcP25UlOGu42dmSSh1w/CAAAAGD7McsKoSQ5M8nHqmqXJHckOSWTMOnjVXVqkjuTvH4Ye0WS45OsSvLwMBYAAACA7cRMgVB335hk+QK7jllgbCc5fQvnBQAAAMCczHKXMQAAAAB2IAIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARkYgBAAAADAyAiEAAACAkREIAQAAAIyMQAgAAABgZARCAAAAACMjEAIAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDICIQAAAICREQgBAAAAjIxACAAAAGBkBEIAAAAAIyMQAgAAABgZgRAAAADAyAiEAAAAAEZGIAQAAAAwMgIhAAAAgJERCAEAAACMzMyBUFXtVFVfq6p/GdoHVtV1VXV7Vf1TVe0y9P/c0F417D9gPlMHAAAAYHM8kRVCb02ycqr9viTnd/eyJA8mOXXoPzXJg939vCTnD+MAAAAA2E7MFAhV1dIkv5XkoqFdSV6Z5JJhyEeSvHbYPmFoZ9h/zDAeAAAAgO3ArCuEPpDknUkeGdp7Jfmf7l47tFcn2W/Y3i/JXUky7H9oGA8AAADAdmCTgVBV/XaS+7r7hunuBYb2DPumX/e0qlpRVSvWrFkz02QBAAAA2HKzrBA6Kslrquq/k1ycyaliH0iyR1XtPIxZmuTuYXt1kv2TZNi/e5IH1n/R7r6wu5d39/IlS5Zs0YcAAAAAYHabDIS6+13dvbS7D0jyhiRf6O4Tk3wxyeuGYScnuWzYvnxoZ9j/he5+3AohAAAAABbHE7nL2PrOSvL2qlqVyTWCPjz0fzjJXkP/25OcvWVTBAAAAGBr2nnTQx7V3VcnuXrYviPJ4QuM+UmS12+FuQEAAAAwB1uyQggAAACAJyGBEAAAAMDICIQAAAAARkYgBAAAADAyAiEAAACAkREIAQAAAIyMQAgAAABgZARCAAAAACMjEAIAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDICIQAAAICREQgBAAAAjIxACAAAAGBkBEIAAAAAIyMQAgAAABgZgRAAAADAyAiEAAAAAEZGIAQAAAAwMgIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARkYgBAAAADAymwyEqmr/qvpiVa2sqlur6q1D/zOr6sqqun34uefQX1X1wapaVVU3V9Vh8/4QAAAAAMxulhVCa5P8UXf/SpIjk5xeVYckOTvJVd29LMlVQztJjkuybHicluRDW33WAAAAAGy2TQZC3X1Pd3912P5BkpVJ9ktyQpKPDMM+kuS1w/YJST7aE9cm2aOq9t3qMwcAAABgszyhawhV1QFJXpzkuiT7dPc9ySQ0SrL3MGy/JHdNPW310AcAAADAdmDmQKiqnp7kE0ne1t3f39jQBfp6gdc7rapWVNWKNWvWzDoNAAAAALbQTIFQVT01kzDoY9196dD93XWngg0/7xv6VyfZf+rpS5Pcvf5rdveF3b28u5cvWbJkc+cPAAAAwBM0y13GKsmHk6zs7vdP7bo8ycnD9slJLpvqP2m429iRSR5ad2oZAAAAAItv5xnGHJXkTUluqaobh75zkpyX5ONVdWqSO5O8fth3RZLjk6xK8nCSU7bqjAEAAADYIpsMhLr737LwdYGS5JgFxneS07dwXgAAAADMyRO6yxgAAAAAT34CIQAAAICREQgBAAAAjIxACAAAAGBkBEIAAAAAIyMQAgAAABgZgRAAAADAyAiEAAAAAEZGIAQAAAAwMgIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARkYgBAAAADAyAiEAAACAkREIAQAAAIyMQAgAAABgZARCAAAAACMjEAIAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDICIQAAAICREQgBAAAAjMxcAqGqOraqbquqVVV19jzeAwAAAIDNs9UDoaraKclfJTkuySFJ3lhVh2zt9wEAAABg88xjhdDhSVZ19x3d/dMkFyc5YQ7vAwAAAMBm2HkOr7lfkrum2quTHDGH99nuLH/v5/PwT9cu9jQAAACALXD1Hx+dvXd72mJPY67mEQjVAn39uEFVpyU5bWj+sKpum8NcIEmeleT+xZ4EPAmoFZiNWoHZqBWYjVrZDu1z7mLPYKv55Q3tmEcgtDrJ/lPtpUnuXn9Qd1+Y5MI5vD88RlWt6O7liz0P2N6pFZiNWoHZqBWYjVphsczjGkLXJ1lWVQdW1S5J3pDk8jm8DwAAAACbYauvEOrutVV1RpLPJtkpyd92961b+30AAAAA2DzzOGUs3X1Fkivm8dqwGZyaCLNRKzAbtQKzUSswG7XCoqjux13vGQAAAIAd2DyuIQQAAADAdkwgxA6pqt5RVV1Vz1qv/6VV9bOqet1U38lVdfvwOHnbzxYWz/q1UlUnVtXNw+Oaqjp0auyxVXVbVa2qqrMXb9aw7S1QK1VVHxzq4eaqOmxqrO8VRqWqzh3q4Maq+lxVPXvo372q/rmqbqqqW6vqlKnnqBNGZ0O1Muw7eui/taq+NNXv+Iu5ccoYO5yq2j/JRUkOTvKS7r5/6N8pyZVJfpLJxc4vqapnJlmRZHmSTnLD8JwHF2XysA0tVCtV9atJVnb3g1V1XJL3dPcRQ/18K8lvJFmdyR0l39jd31is+cO2soFaOT7JmUmOT3JEkguGWvG9wuhU1TO6+/vD9luSHNLdb66qc5Ls3t1nVdWSJLcl+cUkT486YYQ2Uit7JLkmybHdfWdV7d3d9zn+Yt6sEGJHdH6Sd2ZygDHtzCSfSHLfVN9vJrmyux8YDkKuTHLsNpklLL7H1Up3XzN1QH5tkqXD9uFJVnX3Hd390yQXJzlhW04WFtFC3ysnJPloT1ybZI+q2je+Vxihdb/gDnbNo7XSSXarqsokBHogydqoE0ZqI7Xy+0ku7e47h3Hrfl9x/MVczeUuY7BYquo1Sb7T3TdNjj3+v3+/JL+T5JVJXjr1lP2S3DXVXj30wQ5tQ7WynlOTfHrYXqhWjpjfDGH7sJFa2dD3h+8VRqmq/jzJSUkeSvKKofsvk1ye5O4kuyX5ve5+ZDguUyeM0gZq5flJnlpVV2dSKxd090fj+Is5EwjxpFNVn89kufH63p3knCSvXmDfB5Kc1d0/W++AfqHfhJ1HyQ5hM2tl3XNfkUkg9GvruhYYplbYIWxmrWyoJtQKO6SN1Ul3X9bd707y7qp6V5IzkvxpJiuBbszkD3LPTXJlVf1r1Ak7sM2slZ2TvCTJMUl+Psm/V9W1USvMmUCIJ53uftVC/VX1giQHJln3V9ylSb5aVYdnco76xUP/s5IcX1VrM0nZj556maVJrp7X3GFb2pxa6e57q+qFmVwv5bju/t7wtNVJ9p96maWZ/MUXnvQ283tlQzXhe4Ud0obqZAH/kORTmfySe0qS83py0dJVVfVfmVyLS52ww9rMWlmd5P7u/lGSH1XVl5McGsdfzJlrCLHD6O5bunvv7j6guw/I5D/Qw7r73u4+cKr/kiR/0N2fTPLZJK+uqj2ras9M/gr82cX6DLAtbKxWquqXklya5E3d/a2pp12fZFlVHVhVuyR5QyanAcAOa2O1ksm//5OGu40dmeSh7r4nvlcYoapaNtV8TZJvDtt3ZrLiIVW1T5KDktwRdcJIbaRWLkvy8qrauap+IZPTwlbG8RdzZoUQo9bdD1TVuZn8Z5skf9bdDyzmnGCR/UmSvZL89bAiYm13L+/utVV1RiYH7Dtlcqe+WxdxnrDYrsjkDmOrkjycyUoI3yuM1XlVdVCSR5J8O8mbh/5zk/x9Vd2SyakvZ03d/VWdMEYL1kp3r6yqzyS5edh3UXd/PUkcfzFPbjsPAAAAMDJOGQMAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDICIQAAAICREQgBADu0qtqrqm4cHvdW1Xem2tfM6T1fXFUXbWT/kuEWwwAAi2LnxZ4AAMA8dff3krwoSarqPUl+2N1/Mee3PSfJezcypzVVdU9VHdXdX5nzXAAAHscKIQBgtKrqh8PPo6vqS1X18ar6VlWdV1UnVtV/VNUtVfXcYdySqvpEVV0/PI5a4DV3S/LC7r5paP/61Iqkrw37k+STSU7cRh8VAOAxBEIAABOHJnlrkhckeVOS53f34UkuSnLmMOaCJOd390uT/O6wb33Lk3x9qv2OJKd394uSvDzJj4f+FUMbAGCbc8oYAMDE9d19T5JU1X8m+dzQf0uSVwzbr0pySFWte84zqmq37v7B1Ovsm2TNVPsrSd5fVR9Lcml3rx7670vy7K3/MQAANk0gBAAw8b9T249MtR/Jo8dMT0nysu7+cTbsx0metq7R3edV1aeSHJ/k2qp6VXd/cxizsdcBAJgbp4wBAMzuc0nOWNeoqhctMGZlkudNjXlud9/S3e/L5DSxg4ddz89jTy0DANhmBEIAALN7S5LlVXVzVX0jyZvXHzCs/tl96uLRb6uqr1fVTZmsCPr00P+KJJ/aFpMGAFhfdfdizwEAYIdSVX+Y5AfdvdBFp9eN+XKSE7r7wW03MwCACSuEAAC2vg/lsdckeoyqWpLk/cIgAGCxWCEEAAAAMDJWCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARub/AEzNdrtVUHMQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(train_time, scored['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(test_time, scored_test['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "#plt.xlim([-10,-8])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (-350,-250)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "X_train's shape:  (999800, 12)\n",
      "X_test's shape:  (999800, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, train_time = generate_data(\"./data/Ramp21/\", time_range = (-450, -350), window = 2000, step = 10)\n",
    "X_test, test_time = generate_data(\"./data/Ramp21/\", time_range = (-350, -250), window = 2000, step = 10)\n",
    "print(\"X_train's shape: \", X_train.shape)\n",
    "print(\"X_test's shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.3.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                84        \n",
      "=================================================================\n",
      "Total params: 207\n",
      "Trainable params: 207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#================BUILD THE MODEL====================\n",
    "print(\"Using Keras version: \", keras.__version__)\n",
    "\n",
    "# Simple model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'elu', kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(3,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899820 samples, validate on 99980 samples\n",
      "Epoch 1/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 4.6857e-04 - val_loss: 9.3638e-05\n",
      "Epoch 2/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.2114e-04 - val_loss: 6.7140e-05\n",
      "Epoch 3/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 9.9871e-05 - val_loss: 5.5632e-05\n",
      "Epoch 4/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 8.6186e-05 - val_loss: 4.4626e-05\n",
      "Epoch 5/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 7.9346e-05 - val_loss: 4.2514e-05\n",
      "Epoch 6/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.7482e-05 - val_loss: 4.3088e-05\n",
      "Epoch 7/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.6487e-05 - val_loss: 4.2577e-05\n",
      "Epoch 8/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.5841e-05 - val_loss: 4.0843e-05\n",
      "Epoch 9/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.5389e-05 - val_loss: 3.9650e-05\n",
      "Epoch 10/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.4840e-05 - val_loss: 4.1768e-05\n",
      "Epoch 11/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.4284e-05 - val_loss: 3.9312e-05\n",
      "Epoch 12/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 7.3705e-05 - val_loss: 4.1718e-05\n",
      "Epoch 13/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 7.2982e-05 - val_loss: 4.3775e-05\n",
      "Epoch 14/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 7.1925e-05 - val_loss: 3.9808e-05\n",
      "Epoch 15/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.0602e-05 - val_loss: 3.6266e-05\n",
      "Epoch 16/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.9159e-05 - val_loss: 3.7752e-05\n",
      "Epoch 17/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.7825e-05 - val_loss: 3.9813e-05\n",
      "Epoch 18/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 6.6611e-05 - val_loss: 3.5585e-05\n",
      "Epoch 19/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.5803e-05 - val_loss: 3.2871e-05\n",
      "Epoch 20/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.5090e-05 - val_loss: 3.3311e-05\n",
      "Epoch 21/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.4543e-05 - val_loss: 3.3609e-05\n",
      "Epoch 22/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.4176e-05 - val_loss: 3.3128e-05\n",
      "Epoch 23/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.3835e-05 - val_loss: 3.4667e-05\n",
      "Epoch 24/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.3611e-05 - val_loss: 3.2402e-05\n",
      "Epoch 25/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.3465e-05 - val_loss: 3.2658e-05\n",
      "Epoch 26/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.3250e-05 - val_loss: 3.1652e-05\n",
      "Epoch 27/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.3119e-05 - val_loss: 3.1231e-05\n",
      "Epoch 28/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2988e-05 - val_loss: 3.2877e-05\n",
      "Epoch 29/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 6.2913e-05 - val_loss: 3.0394e-05\n",
      "Epoch 30/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2762e-05 - val_loss: 3.1445e-05\n",
      "Epoch 31/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2694e-05 - val_loss: 3.0159e-05\n",
      "Epoch 32/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2626e-05 - val_loss: 2.8424e-05\n",
      "Epoch 33/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2475e-05 - val_loss: 3.1549e-05\n",
      "Epoch 34/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2449e-05 - val_loss: 3.2696e-05\n",
      "Epoch 35/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2386e-05 - val_loss: 3.1576e-05\n",
      "Epoch 36/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 6.2298e-05 - val_loss: 2.9995e-05\n",
      "Epoch 37/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.2251e-05 - val_loss: 3.0719e-05\n",
      "Epoch 38/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2222e-05 - val_loss: 2.9823e-05\n",
      "Epoch 39/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2149e-05 - val_loss: 3.0886e-05\n",
      "Epoch 40/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2115e-05 - val_loss: 3.0085e-05\n",
      "Epoch 41/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2042e-05 - val_loss: 3.1170e-05\n",
      "Epoch 42/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.2019e-05 - val_loss: 3.0962e-05\n",
      "Epoch 43/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1974e-05 - val_loss: 3.1763e-05\n",
      "Epoch 44/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1953e-05 - val_loss: 2.8799e-05\n",
      "Epoch 45/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1877e-05 - val_loss: 2.8030e-05\n",
      "Epoch 46/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1831e-05 - val_loss: 2.7946e-05\n",
      "Epoch 47/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1750e-05 - val_loss: 3.0397e-05\n",
      "Epoch 48/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1710e-05 - val_loss: 2.9167e-05\n",
      "Epoch 49/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1481e-05 - val_loss: 2.8516e-05\n",
      "Epoch 50/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 6.1231e-05 - val_loss: 2.8680e-05\n"
     ]
    }
   ],
   "source": [
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=1028\n",
    "\n",
    "history=model.fit(X_train, X_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mse'] = np.mean(np.abs(X_pred-X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "scored_test = pd.DataFrame()\n",
    "scored_test['Loss_mse'] = np.mean(np.abs(X_pred_test-X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(train_time, scored['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(test_time, scored_test['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "#plt.xlim([-10,-8])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
