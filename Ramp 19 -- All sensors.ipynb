{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/uscms_data/d3/dhoang/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Data processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nptdms import TdmsFile #Process ramping file\n",
    "\n",
    "#For building ML models\n",
    "import keras\n",
    "import keras.models as models\n",
    "from keras.layers.core import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_single_file(filepath):\n",
    "    \"\"\"Read in quench data from a given file, return a pandas dafa frame\"\"\"\n",
    "    \n",
    "    data_dict= {}\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        content = f.readlines()\n",
    "    #Remove`\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    column_names = content[0].split(\" \")\n",
    "    data = [content[i].split(\"   \") for i in range(1, len(content))] \n",
    "    \n",
    "    for i in range(len(column_names)):\n",
    "        data_dict[column_names[i]] = [float(x[i]) for x in data]\n",
    "        \n",
    "    data_frame = pd.DataFrame(data_dict)\n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def read_quench_data(area_path, quench_name):\n",
    "    \"\"\"\n",
    "    Read the quench data from the provided file path, note that there are five quenches so we need to concatenate them together.\n",
    "    Just need to provide the quench's name, for e.g: \"./data/mqxfs1b.Quench.161011115654\"\n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    \n",
    "    num_file = 0 #Number of separate data files for this quench, assuming at least one\n",
    "    \n",
    "    for filename in os.listdir(area_path):\n",
    "        if filename.startswith(quench_name) and not filename.endswith(\".tar.gz\"):\n",
    "            #print(\"Reading file ... \" + filename)\n",
    "            if num_file == 0:\n",
    "                try:\n",
    "                    data_list.append(read_data_from_single_file(area_path + filename)) #read first file separately\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                try:\n",
    "                    data_list.append(read_data_from_single_file(area_path + filename).drop(columns = [\"time\"])) #Time is already saved in the first file\n",
    "                except:\n",
    "                    pass\n",
    "            num_file += 1\n",
    "                                 \n",
    "    #print(\"Total number of data files for {}: \".format(quench_name), num_file)\n",
    "    \n",
    "    if len(data_list) != 0:\n",
    "        data = pd.concat(data_list, axis = 1) #Concatenate all data files together\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Returning None due to file errors in \" + quench_name)\n",
    "        return None\n",
    "\n",
    "def read_all_quench_in_area(area_path):\n",
    "    \"\"\"\n",
    "    Read all quench's files in the area and return a dictionary of different quench's data. name is the magnet's name\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    index = 1 #For indexing different quench\n",
    "\n",
    "    for filename in os.listdir(area_path):\n",
    "        if filename.endswith(\".tar.gz\"): \n",
    "            #print(\"Reading data from ... \" + filename[0:-7])\n",
    "            data[filename[0:-7]] = read_quench_data(area_path, filename[0:-7])\n",
    "            index += 1\n",
    "            \n",
    "    #print(\"Completed. There are {} quenches in total.\".format(str(index - 1)))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def plot_variables_with_time(data, variables = None, time_range = None):\n",
    "    \"\"\"\n",
    "    Take a data frame, and plot all other variables with time.\n",
    "    Optional argument: time_range to specify the range to plot, default is to plot all time. Example argument\n",
    "    is (start_time, end_time)\n",
    "    \"\"\"\n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "        \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    if variables:\n",
    "        for variable in variables:\n",
    "            plt.figure(figsize=(20,2))\n",
    "            plt.plot(data[\"time\"], data[variable])\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.title(\"Variable {}\".format(variable))\n",
    "            plt.show()\n",
    "        \n",
    "    else:      \n",
    "        #If variables not specified then just plot all \n",
    "        for variable in data.columns[1:]:\n",
    "            plt.figure(figsize=(25,2))\n",
    "            plt.plot(data[\"time\"], data[variable])\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.title(\"Variable {}\".format(variable))\n",
    "            plt.show()\n",
    "\n",
    "def plot_statistics(data, variables = None, time_range = None, window = 100):\n",
    "    \"\"\"Take a data frame and plot the variable with its moving average and real data in the specified range, if\n",
    "    variables are not specified then just plot all variables by default\"\"\"\n",
    "    #Pickout the data\n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "        \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    def plot_signal_and_statistics(variable):\n",
    "        # Plotted by calculating Simple Moving Average (SMA)\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data[variable], label = \"Signal with noise\")\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).mean(),label = \"Moving average\")\n",
    "        #plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).min(),label = \"Moving min\")\n",
    "        #plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).max(),label = \"Moving max\")\n",
    "        plt.legend(loc = \"best\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        #Variance\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).std(),\n",
    "                 label = \"Variance\",\n",
    "                 color = 'red')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}'s Variance\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        #Kurtosis\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).kurt(),\n",
    "                 label = \"Kurtosis\",\n",
    "                 color = 'green')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}'s Kurtosis\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        #Skew\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).skew(),\n",
    "                 label = \"Skew\",\n",
    "                 color = 'purple')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}'s Skew\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        \"\"\"\n",
    "        #Quantile\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).quantile(0.25), label = \"Quantile 25\",\n",
    "                 color = 'red')\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).quantile(0.75), label = \"Quantile 75\",\n",
    "                 color = 'orange')\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).quantile(0.50), label = \"Quantile 50\",\n",
    "                 color = 'green')\n",
    "        plt.legend(loc = \"best\")\n",
    "        plt.title(\"Variable {}'s Quantile\".format(variable))\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "    #Plot\n",
    "    if variables:\n",
    "        for variable in variables:\n",
    "            print(variable)\n",
    "            plot_signal_and_statistics(variable)         \n",
    "    else:\n",
    "        for variable in data.columns[1:]:\n",
    "            print(variable)\n",
    "            plot_signal_and_statistics(variable)\n",
    "    \n",
    "    %reset -f in\n",
    "\n",
    "def plot_variable(data_dict, variable, time_range = None, window = 100):\n",
    "    for quench_name in data_dict.keys():\n",
    "        print(\"Quench's index: \" + quench_name)\n",
    "        if data_dict[quench_name] is not None:\n",
    "            if variable[0] in list(data_dict[quench_name].columns):\n",
    "                plot_statistics(data_dict[quench_name], variables = variable, time_range=time_range, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_single_file(filepath):\n",
    "    \"\"\"Read in quench data from a given file, return a pandas dafa frame\"\"\"\n",
    "    \n",
    "    data_dict= {}\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        content = f.readlines()\n",
    "    #Remove`\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    column_names = content[0].split(\" \")\n",
    "    data = [content[i].split(\"   \") for i in range(1, len(content))] \n",
    "    \n",
    "    for i in range(len(column_names)):\n",
    "        data_dict[column_names[i]] = [float(x[i]) for x in data]\n",
    "        \n",
    "    data_frame = pd.DataFrame(data_dict)\n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def read_quench_data(area_path, quench_name):\n",
    "    \"\"\"\n",
    "    Read the quench data from the provided file path, note that there are five quenches so we need to concatenate them together.\n",
    "    Just need to provide the quench's name, for e.g: \"./data/mqxfs1b.Quench.161011115654\"\n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    \n",
    "    num_file = 0 #Number of separate data files for this quench, assuming at least one\n",
    "    \n",
    "    for filename in os.listdir(area_path):\n",
    "        if filename.startswith(quench_name) and not filename.endswith(\".tar.gz\"):\n",
    "            #print(\"Reading file ... \" + filename)\n",
    "            if num_file == 0:\n",
    "                try:\n",
    "                    data_list.append(read_data_from_single_file(area_path + filename)) #read first file separately\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                try:\n",
    "                    data_list.append(read_data_from_single_file(area_path + filename).drop(columns = [\"time\"])) #Time is already saved in the first file\n",
    "                except:\n",
    "                    pass\n",
    "            num_file += 1\n",
    "                                 \n",
    "    #print(\"Total number of data files for {}: \".format(quench_name), num_file)\n",
    "    \n",
    "    if len(data_list) != 0:\n",
    "        data = pd.concat(data_list, axis = 1) #Concatenate all data files together\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Returning None due to file errors in \" + quench_name)\n",
    "        return None\n",
    "\n",
    "def read_all_quench_in_area(area_path):\n",
    "    \"\"\"\n",
    "    Read all quench's files in the area and return a dictionary of different quench's data. name is the magnet's name\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    index = 1 #For indexing different quench\n",
    "\n",
    "    for filename in os.listdir(area_path):\n",
    "        if filename.endswith(\".tar.gz\"): \n",
    "            #print(\"Reading data from ... \" + filename[0:-7])\n",
    "            data[filename[0:-7]] = read_quench_data(area_path, filename[0:-7])\n",
    "            index += 1\n",
    "            \n",
    "    #print(\"Completed. There are {} quenches in total.\".format(str(index - 1)))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def plot_variables_with_time(data, variables = None, time_range = None):\n",
    "    \"\"\"\n",
    "    Take a data frame, and plot all other variables with time.\n",
    "    Optional argument: time_range to specify the range to plot, default is to plot all time. Example argument\n",
    "    is (start_time, end_time)\n",
    "    \"\"\"\n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "        \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    if variables:\n",
    "        for variable in variables:\n",
    "            plt.figure(figsize=(20,2))\n",
    "            plt.plot(data[\"time\"], data[variable])\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.title(\"Variable {}\".format(variable))\n",
    "            plt.show()\n",
    "        \n",
    "    else:      \n",
    "        #If variables not specified then just plot all \n",
    "        for variable in data.columns[1:]:\n",
    "            plt.figure(figsize=(25,2))\n",
    "            plt.plot(data[\"time\"], data[variable])\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.title(\"Variable {}\".format(variable))\n",
    "            plt.show()\n",
    "\n",
    "def plot_statistics(data, variables = None, time_range = None, window = 100):\n",
    "    \"\"\"Take a data frame and plot the variable with its moving average and real data in the specified range, if\n",
    "    variables are not specified then just plot all variables by default\"\"\"\n",
    "    #Pickout the data\n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "        \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    def plot_signal_and_statistics(variable):\n",
    "        # Plotted by calculating Simple Moving Average (SMA)\n",
    "        plt.figure(figsize=(20,2))\n",
    "        \n",
    "        plt.plot(data[\"time\"], data[variable], label = \"Signal with noise\")\n",
    "        \n",
    "        #plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).mean(),label = \"Moving average\")\n",
    "        #plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).min(),label = \"Moving min\")\n",
    "        #plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).max(),label = \"Moving max\")\n",
    "        plt.legend(loc = \"best\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        #Variance\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).std(),\n",
    "                 label = \"Standard Deviation\",\n",
    "                 color = 'red')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}'s Standard Deviation\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        #Kurtosis\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).kurt(),\n",
    "                 label = \"Kurtosis\",\n",
    "                 color = 'green')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}'s Kurtosis\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        #Skew\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).skew(),\n",
    "                 label = \"Skew\",\n",
    "                 color = 'purple')\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.title(\"Variable {}'s Skew\".format(variable))\n",
    "        plt.show()\n",
    "        \n",
    "        \"\"\"\n",
    "        #Quantile\n",
    "        plt.figure(figsize=(20,2))\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).quantile(0.25), label = \"Quantile 25\",\n",
    "                 color = 'red')\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).quantile(0.75), label = \"Quantile 75\",\n",
    "                 color = 'orange')\n",
    "        plt.plot(data[\"time\"], data.loc[:, variable].rolling(window=window).quantile(0.50), label = \"Quantile 50\",\n",
    "                 color = 'green')\n",
    "        plt.legend(loc = \"best\")\n",
    "        plt.title(\"Variable {}'s Quantile\".format(variable))\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "    #Plot\n",
    "    if variables:\n",
    "        for variable in variables:\n",
    "            print(variable)\n",
    "            plot_signal_and_statistics(variable)         \n",
    "    else:\n",
    "        for variable in data.columns[1:]:\n",
    "            print(variable)\n",
    "            plot_signal_and_statistics(variable)\n",
    "    \n",
    "    %reset -f in\n",
    "\n",
    "def plot_variable(data_dict, variable, time_range = None, window = 100):\n",
    "    for quench_name in data_dict.keys():\n",
    "        print(\"Quench's index: \" + quench_name)\n",
    "        if data_dict[quench_name] is not None:\n",
    "            if variable[0] in list(data_dict[quench_name].columns):\n",
    "                plot_statistics(data_dict[quench_name], variables = variable, time_range=time_range, window=window)\n",
    "\n",
    "\n",
    "########### PROCESS RAMPING DATA ###############\n",
    "def read_tdms_file(filepath):\n",
    "    \"\"\"Read the tdms file from a given path, return a pandas data frame of the tdms file\"\"\"\n",
    "    tdms_file = TdmsFile.read(data_path)\n",
    "    \n",
    "    data_frame = tdms_file.as_dataframe()\n",
    "    \n",
    "    del tdms_file\n",
    "    \n",
    "    #Just the last 3 symbols in columns name matter ('/'_unnamedTask<3>'/'PXI2Slot14/ai0') -> ai0\n",
    "    #Rename the columns\n",
    "    rename_map = []\n",
    "    \n",
    "    for column in data_frame.columns:\n",
    "        rename_map.append(column[-4:-1])\n",
    "    \n",
    "    data_frame.columns = rename_map\n",
    "    \n",
    "    #Add time axis relative to the time when quench happens\n",
    "    time_range = np.asarray(range(data_frame.shape[0]))\n",
    "    \n",
    "\n",
    "    #Center around the max value (quench happens at 0 time)\n",
    "    max_index = data_frame['ai7'].idxmax()\n",
    "    time_range -= max_index\n",
    "    time_range = time_range.astype('float32')\n",
    "    \n",
    "    #Multiply by datarate\n",
    "    time_range = np.multiply(time_range, 1e-5, out=time_range, casting=\"unsafe\")\n",
    "    \n",
    "    data_frame['time'] = time_range\n",
    "    \n",
    "    return data_frame\n",
    "\n",
    "def break_tdms_to_files(file_path):\n",
    "    \"\"\"Read the tdms file and break it into several files according to channels in a new directory\"\"\"\n",
    "    tdms_file = TdmsFile.read(file_path)\n",
    "    \n",
    "    data_frame = tdms_file.as_dataframe()\n",
    "    \n",
    "    del tdms_file\n",
    "    \n",
    "    os.mkdir(\"./data/\" + file_path[-10:-5])\n",
    "    \n",
    "    for channel in data_frame.columns:\n",
    "        np.save(\"./data/{}/{}\".format(file_path[-10:-5], channel[-4:-1]), data_frame.loc[:, channel].to_numpy())\n",
    "\n",
    "def calculate_time(dir_path):\n",
    "    \"\"\"Take a tdms file directory path (after the file is broken up), and calculate and output a time file.\"\"\"\n",
    "    \n",
    "    ai7 = np.load(dir_path + \"ai7.npy\")\n",
    "    \n",
    "    #Add time axis relative to the time when quench happens\n",
    "    time_range = np.asarray(range(ai7.shape[0]))\n",
    "    \n",
    "    #Center around the max value (quench happens at 0 time)\n",
    "    max_index = np.argmax(ai7)\n",
    "    time_range -= max_index\n",
    "    time_range = time_range.astype('float32')\n",
    "    \n",
    "    #Multiply by datarate\n",
    "    time_range = np.multiply(time_range, 1e-5, out=time_range, casting=\"unsafe\")\n",
    "    \n",
    "    np.save(dir_path + \"time\", time_range)\n",
    "\n",
    "def load_channel_and_time(dir_path, channel):\n",
    "    data_frame = pd.DataFrame(data = {channel: np.load(dir_path + channel + \".npy\"),\n",
    "                                     \"time\": np.load(dir_path + \"time.npy\")})\n",
    "    return data_frame\n",
    "\n",
    "def plot_channel(data, channel, time_range = None):\n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "        \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(data[\"time\"], data[channel])\n",
    "    plt.title(\"Variable {}\".format(channel))\n",
    "    plt.show()\n",
    "    \n",
    "    %reset -f in\n",
    "\n",
    "def load_and_plot(dir_path, channel, time_range = None, stat = False, window = 100):\n",
    "    ai = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    if stat:\n",
    "        plot_statistics(ai, variables = [channel], time_range = time_range, window = window)\n",
    "    else:\n",
    "        plot_channel(ai, channel, time_range = time_range)\n",
    "    \n",
    "    %reset -f in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    #data[\"Mean\"] = data.loc[:, channel].rolling(window=window).mean()\n",
    "    data[\"SD\"] = data.loc[:, channel].rolling(window=window).std()\n",
    "    data[\"Kurtosis\"] = data.loc[:, channel].rolling(window=window).kurt()\n",
    "    data[\"Skew\"] = data.loc[:, channel].rolling(window=window).skew()\n",
    "    \n",
    "    select_list = [channel, \"SD\", \"Kurtosis\", \"Skew\"]\n",
    "    \n",
    "    assert data[select_list].to_numpy()[window-1::step].shape[0] == data['time'].to_numpy()[window-1::step].shape[0]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return data[select_list].to_numpy()[window-1::step], data['time'].to_numpy()[window-1::step]\n",
    "\n",
    "def generate_data_no_time(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    #data[\"Mean\"] = data.loc[:, channel].rolling(window=window).mean()\n",
    "    data[\"SD\"] = data.loc[:, channel].rolling(window=window).std()\n",
    "    data[\"Kurtosis\"] = data.loc[:, channel].rolling(window=window).kurt()\n",
    "    data[\"Skew\"] = data.loc[:, channel].rolling(window=window).skew()\n",
    "    \n",
    "    select_list = [channel, \"SD\", \"Kurtosis\", \"Skew\"]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return data[select_list].to_numpy()[window-1::step]\n",
    "\n",
    "def generate_data_all_sensors(dir_path, time_range, window = 1000, step = 10):\n",
    "    \n",
    "    ai0, time = generate_data(dir_path, \"ai0\", time_range = time_range, window = window, step = step)\n",
    "    ai1 = generate_data_no_time(dir_path, \"ai1\", time_range = time_range, window = window, step = step)\n",
    "    ai2 = generate_data_no_time(dir_path, \"ai2\", time_range = time_range, window = window, step = step)\n",
    "    ai3 = generate_data_no_time(dir_path, \"ai3\", time_range = time_range, window = window, step = step)\n",
    "    ai4 = generate_data_no_time(dir_path, \"ai4\", time_range = time_range, window = window, step = step)\n",
    "    \n",
    "    all_channels = np.concatenate((ai0,ai1,ai2,ai3,ai4), axis = 1)\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_channels, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
