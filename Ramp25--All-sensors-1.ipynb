{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ramp 25 - variances + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/uscms_data/d3/dhoang/miniconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Data processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nptdms import TdmsFile #Process ramping file\n",
    "\n",
    "#For building ML models\n",
    "import keras\n",
    "import keras.models as models\n",
    "from keras.layers.core import Dense\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_and_time(dir_path, channel):\n",
    "    data_frame = pd.DataFrame(data = {channel: np.load(dir_path + channel + \".npy\"),\n",
    "                                     \"time\": np.load(dir_path + \"time.npy\")})\n",
    "    return data_frame\n",
    "    \n",
    "def generate_data_0(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    #data[\"Mean\"] = data.loc[:, channel].abs().rolling(window=window).mean()\n",
    "    data[\"SD\"] = data.loc[:, channel].rolling(window=window).std()\n",
    "    #data[\"Kurtosis\"] = data.loc[:, channel].rolling(window=window).kurt()\n",
    "    #data[\"Skew\"] = data.loc[:, channel].rolling(window=window).skew()\n",
    "    \n",
    "    select_list = [\"SD\"]\n",
    "    \n",
    "    assert data[select_list].to_numpy()[window-1::step].shape[0] == data['time'].to_numpy()[window-1::step].shape[0]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return data[select_list].to_numpy()[window-1::step], data['time'].to_numpy()[window-1::step]\n",
    "\n",
    "def generate_data_no_time(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the statistics\n",
    "    #data[\"Mean\"] = data.loc[:, channel].abs().rolling(window=window).mean()\n",
    "    data[\"SD\"] = data.loc[:, channel].rolling(window=window).std()\n",
    "    #data[\"Kurtosis\"] = data.loc[:, channel].rolling(window=window).kurt()\n",
    "    #data[\"Skew\"] = data.loc[:, channel].rolling(window=window).skew()\n",
    "    \n",
    "    select_list = [\"SD\"]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return data[select_list].to_numpy()[window-1::step]\n",
    "\n",
    "def generate_data_all_sensors(dir_path, time_range, window = 1000, step = 10):\n",
    "    \n",
    "    ai0, time = generate_data(dir_path, \"ai0\", time_range = time_range, window = window, step = step)\n",
    "    ai1 = generate_data_no_time(dir_path, \"ai1\", time_range = time_range, window = window, step = step)\n",
    "    ai2 = generate_data_no_time(dir_path, \"ai2\", time_range = time_range, window = window, step = step)\n",
    "    ai3 = generate_data_no_time(dir_path, \"ai3\", time_range = time_range, window = window, step = step)\n",
    "    ai4 = generate_data_no_time(dir_path, \"ai4\", time_range = time_range, window = window, step = step)\n",
    "    \n",
    "    #Multiply them all together\n",
    "    product_var = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    \n",
    "    all_channels = np.concatenate((ai0,ai1,ai2,ai3,ai4,product_var), axis = 1)\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_channels, time\n",
    "\n",
    "def plot_moving_mean(dir_path, channel, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the mean\n",
    "    data[\"Mean\"] = data.loc[:, channel].abs().rolling(window=window).mean()\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(data['time'].to_numpy()[window-1::step], data[\"Mean\"].to_numpy()[window-1::step], label = \"Mean of abs(data)\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Sensor {}'s moving mean\".format(channel))\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "def load_sensor(dir_path, sensor, time_range = None):\n",
    "    \n",
    "    data = pd.DataFrame(data = {sensor: np.load(dir_path + sensor + \".npy\"),\n",
    "                                \"time\": np.load(dir_path + \"time.npy\")})\n",
    "    \n",
    "    start = min(data[\"time\"])\n",
    "    end = max(data[\"time\"])\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "    \n",
    "    \n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "   \n",
    "    %reset -f in\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def plot_product_mean(dir_path, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    \n",
    "    time_axis = ai0['time'].to_numpy()[window-1::step]\n",
    "    \n",
    "    ai0 = ai0[\"ai0\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    \n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(time_axis, product)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Product of moving means\")\n",
    "    \n",
    "def plot_SD(dir_path, channel, time_range, window = 2000, step = 10):\n",
    "    \n",
    "    #Load the data\n",
    "    data = load_channel_and_time(dir_path, channel)\n",
    "    \n",
    "    #Select the part\n",
    "    start = time_range[0]\n",
    "    end = time_range[1]\n",
    "    data = data[(data[\"time\"] > start) & (data[\"time\"] < end)]\n",
    "    \n",
    "    #Calculate the mean\n",
    "    data[\"SD\"] = data.loc[:, channel].abs().rolling(window=window).std()\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(data['time'].to_numpy()[window-1::step], data[\"SD\"].to_numpy()[window-1::step], label = \"Standard deviation\", color = \"red\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Sensor {}'s moving standard deviation\".format(channel))\n",
    "    \n",
    "    %reset -f in\n",
    "\n",
    "\n",
    "def plot_product_SD(dir_path, time_range, window = 1000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    \n",
    "    time_axis = ai0['time'].to_numpy()[window-1::step]\n",
    "    \n",
    "    ai0 = ai0[\"ai0\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    \n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Plot\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.plot(time_axis, product, color = \"red\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(\"Product of moving standard deviations\")\n",
    "    \n",
    "def generate_mean_data(dir_path, time_range, window = 2000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)[\"ai0\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].abs().rolling(window=window).mean().to_numpy()[window-1::step]\n",
    "    \n",
    "    #Calculate the product\n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Stack them together\n",
    "    all_mean = np.vstack((ai0,ai1,ai2,ai3,ai4, product)).transpose()\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_mean\n",
    "\n",
    "def generate_sd_data(dir_path, time_range, window = 2000, step = 10):\n",
    "    #Load the data\n",
    "    ai0 = load_sensor(dir_path, \"ai0\", time_range = time_range)[\"ai0\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai1 = load_sensor(dir_path, \"ai1\", time_range = time_range)[\"ai1\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai2 = load_sensor(dir_path, \"ai2\", time_range = time_range)[\"ai2\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai3 = load_sensor(dir_path, \"ai3\", time_range = time_range)[\"ai3\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    ai4 = load_sensor(dir_path, \"ai4\", time_range = time_range)[\"ai4\"].rolling(window=window).std().to_numpy()[window-1::step]\n",
    "    \n",
    "    #Calculate the product\n",
    "    product = ai0*ai1*ai2*ai3*ai4\n",
    "    \n",
    "    #Stack them together\n",
    "    all_sd = np.vstack((ai0,ai1,ai2,ai3,ai4, product)).transpose()\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_sd\n",
    "\n",
    "def load_time_label(dir_path, time_range, window = 2000, step = 10):\n",
    "    \n",
    "    time_label =  np.load(dir_path + \"time.npy\")\n",
    "    \n",
    "    start = min(time_label)\n",
    "    end = max(time_label)\n",
    "    \n",
    "    if time_range:\n",
    "        start = time_range[0]\n",
    "        end = time_range[1]\n",
    "    \n",
    "    \n",
    "    time_label = time_label[(time_label > start) & (time_label < end)][window-1::step]\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return time_label\n",
    "    \n",
    "\n",
    "def generate_data(dir_path, time_range, window = 2000, step = 10):\n",
    "    \n",
    "    moving_mean = generate_mean_data(dir_path, time_range, window = 2000, step = 10)\n",
    "    moving_sd = generate_sd_data(dir_path, time_range, window = 2000, step = 10)\n",
    "    time_label = load_time_label(dir_path, time_range, window = 2000, step = 10)\n",
    "    \n",
    "    all_data = np.concatenate((moving_mean, moving_sd), axis = 1)\n",
    "    \n",
    "    %reset -f in\n",
    "    \n",
    "    return all_data, time_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "X_train's shape:  (999800, 12)\n",
      "X_test's shape:  (499800, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, train_time = generate_data(\"./data/Ramp25/\", time_range = (-450, -350), window = 2000, step = 10)\n",
    "X_test, test_time = generate_data(\"./data/Ramp25/\", time_range = (-50, 0), window = 2000, step = 10)\n",
    "print(\"X_train's shape: \", X_train.shape)\n",
    "print(\"X_test's shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.3.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                84        \n",
      "=================================================================\n",
      "Total params: 207\n",
      "Trainable params: 207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#================BUILD THE MODEL====================\n",
    "print(\"Using Keras version: \", keras.__version__)\n",
    "\n",
    "# Simple model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'elu', kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(3,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899820 samples, validate on 99980 samples\n",
      "Epoch 1/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 6.1312e-04 - val_loss: 3.8830e-04\n",
      "Epoch 2/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 2.2598e-04 - val_loss: 3.1388e-04\n",
      "Epoch 3/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 2.0373e-04 - val_loss: 2.8936e-04\n",
      "Epoch 4/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.9675e-04 - val_loss: 2.7537e-04\n",
      "Epoch 5/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.9148e-04 - val_loss: 2.6314e-04\n",
      "Epoch 6/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.8162e-04 - val_loss: 2.5936e-04\n",
      "Epoch 7/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.7150e-04 - val_loss: 2.4783e-04\n",
      "Epoch 8/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.6283e-04 - val_loss: 2.3048e-04\n",
      "Epoch 9/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.5115e-04 - val_loss: 2.1710e-04\n",
      "Epoch 10/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.4420e-04 - val_loss: 2.1472e-04\n",
      "Epoch 11/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.4063e-04 - val_loss: 2.0768e-04\n",
      "Epoch 12/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.3829e-04 - val_loss: 2.0708e-04\n",
      "Epoch 13/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3646e-04 - val_loss: 2.0698e-04\n",
      "Epoch 14/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.3473e-04 - val_loss: 1.9909e-04\n",
      "Epoch 15/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.3264e-04 - val_loss: 1.9756e-04\n",
      "Epoch 16/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.3053e-04 - val_loss: 1.8508e-04\n",
      "Epoch 17/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2868e-04 - val_loss: 1.8983e-04\n",
      "Epoch 18/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2714e-04 - val_loss: 1.8683e-04\n",
      "Epoch 19/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2590e-04 - val_loss: 1.8989e-04\n",
      "Epoch 20/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2479e-04 - val_loss: 1.8581e-04\n",
      "Epoch 21/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2384e-04 - val_loss: 1.8475e-04\n",
      "Epoch 22/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2297e-04 - val_loss: 1.8479e-04\n",
      "Epoch 23/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 1.2183e-04 - val_loss: 1.8166e-04\n",
      "Epoch 24/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2079e-04 - val_loss: 1.8582e-04\n",
      "Epoch 25/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1973e-04 - val_loss: 1.8402e-04\n",
      "Epoch 26/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1860e-04 - val_loss: 1.8491e-04\n",
      "Epoch 27/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1761e-04 - val_loss: 1.8488e-04\n",
      "Epoch 28/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1674e-04 - val_loss: 1.8307e-04\n",
      "Epoch 29/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1615e-04 - val_loss: 1.8602e-04\n",
      "Epoch 30/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1572e-04 - val_loss: 1.8698e-04\n",
      "Epoch 31/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1522e-04 - val_loss: 1.8112e-04\n",
      "Epoch 32/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1485e-04 - val_loss: 1.9067e-04\n",
      "Epoch 33/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1457e-04 - val_loss: 1.8065e-04\n",
      "Epoch 34/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1425e-04 - val_loss: 1.7799e-04\n",
      "Epoch 35/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1404e-04 - val_loss: 1.8046e-04\n",
      "Epoch 36/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1381e-04 - val_loss: 1.7952e-04\n",
      "Epoch 37/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.1363e-04 - val_loss: 1.8105e-04\n",
      "Epoch 38/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1343e-04 - val_loss: 1.7800e-04\n",
      "Epoch 39/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1323e-04 - val_loss: 1.8136e-04\n",
      "Epoch 40/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1308e-04 - val_loss: 1.8174e-04\n",
      "Epoch 41/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1288e-04 - val_loss: 1.8023e-04\n",
      "Epoch 42/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1275e-04 - val_loss: 1.7906e-04\n",
      "Epoch 43/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1259e-04 - val_loss: 1.8035e-04\n",
      "Epoch 44/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1255e-04 - val_loss: 1.7899e-04\n",
      "Epoch 45/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 1.1233e-04 - val_loss: 1.8004e-04\n",
      "Epoch 46/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1210e-04 - val_loss: 1.7407e-04\n",
      "Epoch 47/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.1190e-04 - val_loss: 1.8009e-04\n",
      "Epoch 48/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1174e-04 - val_loss: 1.7195e-04\n",
      "Epoch 49/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1155e-04 - val_loss: 1.8160e-04\n",
      "Epoch 50/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.1148e-04 - val_loss: 1.7111e-04\n"
     ]
    }
   ],
   "source": [
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=1028\n",
    "\n",
    "history=model.fit(X_train, X_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mse'] = np.mean(np.abs(X_pred-X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "scored_test = pd.DataFrame()\n",
    "scored_test['Loss_mse'] = np.mean(np.abs(X_pred_test-X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(train_time, scored['Loss_mse'])\n",
    "plt.ylim([0, 400])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(test_time, scored_test['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlim([-10,-8])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Try on other testing ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (-200,-50)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "X_train's shape:  (999800, 12)\n",
      "X_test's shape:  (1499800, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, train_time = generate_data(\"./data/Ramp25/\", time_range = (-450, -350), window = 2000, step = 10)\n",
    "X_test, test_time = generate_data(\"./data/Ramp25/\", time_range = (-200, -50), window = 2000, step = 10)\n",
    "print(\"X_train's shape: \", X_train.shape)\n",
    "print(\"X_test's shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.3.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                84        \n",
      "=================================================================\n",
      "Total params: 207\n",
      "Trainable params: 207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#================BUILD THE MODEL====================\n",
    "print(\"Using Keras version: \", keras.__version__)\n",
    "\n",
    "# Simple model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'elu', kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(3,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899820 samples, validate on 99980 samples\n",
      "Epoch 1/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 7.6845e-04 - val_loss: 4.0405e-04\n",
      "Epoch 2/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 2.3387e-04 - val_loss: 3.1587e-04\n",
      "Epoch 3/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 2.1793e-04 - val_loss: 3.0370e-04\n",
      "Epoch 4/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 2.1363e-04 - val_loss: 2.9316e-04\n",
      "Epoch 5/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 2.1008e-04 - val_loss: 2.8743e-04\n",
      "Epoch 6/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 2.0442e-04 - val_loss: 2.8394e-04\n",
      "Epoch 7/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.9540e-04 - val_loss: 2.7140e-04\n",
      "Epoch 8/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.8391e-04 - val_loss: 2.5842e-04\n",
      "Epoch 9/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.7234e-04 - val_loss: 2.4730e-04\n",
      "Epoch 10/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.5449e-04 - val_loss: 2.2774e-04\n",
      "Epoch 11/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.4634e-04 - val_loss: 2.2469e-04\n",
      "Epoch 12/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.4378e-04 - val_loss: 2.2108e-04\n",
      "Epoch 13/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.4181e-04 - val_loss: 2.1610e-04\n",
      "Epoch 14/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3988e-04 - val_loss: 2.2082e-04\n",
      "Epoch 15/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3782e-04 - val_loss: 2.1640e-04\n",
      "Epoch 16/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3537e-04 - val_loss: 2.1292e-04\n",
      "Epoch 17/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3312e-04 - val_loss: 2.1107e-04\n",
      "Epoch 18/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3126e-04 - val_loss: 2.0555e-04\n",
      "Epoch 19/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2969e-04 - val_loss: 2.0251e-04\n",
      "Epoch 20/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2841e-04 - val_loss: 1.9838e-04\n",
      "Epoch 21/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2736e-04 - val_loss: 1.9570e-04\n",
      "Epoch 22/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2646e-04 - val_loss: 1.9333e-04\n",
      "Epoch 23/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2568e-04 - val_loss: 1.9399e-04\n",
      "Epoch 24/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2505e-04 - val_loss: 1.9687e-04\n",
      "Epoch 25/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2452e-04 - val_loss: 1.9240e-04\n",
      "Epoch 26/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2399e-04 - val_loss: 1.8898e-04\n",
      "Epoch 27/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2360e-04 - val_loss: 1.9295e-04\n",
      "Epoch 28/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2322e-04 - val_loss: 1.8841e-04\n",
      "Epoch 29/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 1.2293e-04 - val_loss: 1.8746e-04\n",
      "Epoch 30/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 1.2259e-04 - val_loss: 1.8334e-04\n",
      "Epoch 31/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2231e-04 - val_loss: 1.8507e-04\n",
      "Epoch 32/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2209e-04 - val_loss: 1.8277e-04\n",
      "Epoch 33/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 1.2182e-04 - val_loss: 1.8406e-04\n",
      "Epoch 34/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2166e-04 - val_loss: 1.8275e-04\n",
      "Epoch 35/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2141e-04 - val_loss: 1.8550e-04\n",
      "Epoch 36/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2116e-04 - val_loss: 1.8246e-04\n",
      "Epoch 37/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.2096e-04 - val_loss: 1.8388e-04\n",
      "Epoch 38/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2081e-04 - val_loss: 1.8415e-04\n",
      "Epoch 39/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2062e-04 - val_loss: 1.8340e-04\n",
      "Epoch 40/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2045e-04 - val_loss: 1.8325e-04\n",
      "Epoch 41/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2028e-04 - val_loss: 1.8242e-04\n",
      "Epoch 42/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2011e-04 - val_loss: 1.8239e-04\n",
      "Epoch 43/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1992e-04 - val_loss: 1.7936e-04\n",
      "Epoch 44/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1976e-04 - val_loss: 1.8159e-04\n",
      "Epoch 45/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.1960e-04 - val_loss: 1.7830e-04\n",
      "Epoch 46/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1945e-04 - val_loss: 1.7948e-04\n",
      "Epoch 47/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1932e-04 - val_loss: 1.8016e-04\n",
      "Epoch 48/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1913e-04 - val_loss: 1.8112e-04\n",
      "Epoch 49/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1903e-04 - val_loss: 1.7691e-04\n",
      "Epoch 50/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1880e-04 - val_loss: 1.7622e-04\n"
     ]
    }
   ],
   "source": [
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=1028\n",
    "\n",
    "history=model.fit(X_train, X_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mse'] = np.mean(np.abs(X_pred-X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "scored_test = pd.DataFrame()\n",
    "scored_test['Loss_mse'] = np.mean(np.abs(X_pred_test-X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(train_time, scored['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(test_time, scored_test['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "#plt.xlim([-10,-8])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 (-350,-200)s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "Flushing input history\n",
      "X_train's shape:  (999800, 12)\n",
      "X_test's shape:  (499800, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, train_time = generate_data(\"./data/Ramp25/\", time_range = (-450, -350), window = 2000, step = 10)\n",
    "X_test, test_time = generate_data(\"./data/Ramp25/\", time_range = (-350, -300), window = 2000, step = 10)\n",
    "print(\"X_train's shape: \", X_train.shape)\n",
    "print(\"X_test's shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Keras version:  2.3.1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                84        \n",
      "=================================================================\n",
      "Total params: 207\n",
      "Trainable params: 207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#================BUILD THE MODEL====================\n",
    "print(\"Using Keras version: \", keras.__version__)\n",
    "\n",
    "# Simple model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(6, activation = 'elu', kernel_initializer='glorot_uniform',\n",
    "                kernel_regularizer=regularizers.l2(0.0),\n",
    "                input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(3,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(6,activation='elu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(X_train.shape[1],\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 899820 samples, validate on 99980 samples\n",
      "Epoch 1/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 8.5004e-04 - val_loss: 3.6043e-04\n",
      "Epoch 2/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 2.3564e-04 - val_loss: 3.0532e-04\n",
      "Epoch 3/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 2.1866e-04 - val_loss: 2.9473e-04\n",
      "Epoch 4/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 2.1210e-04 - val_loss: 2.8688e-04\n",
      "Epoch 5/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 2.0421e-04 - val_loss: 2.9056e-04\n",
      "Epoch 6/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.9457e-04 - val_loss: 2.8897e-04\n",
      "Epoch 7/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.8174e-04 - val_loss: 2.6797e-04\n",
      "Epoch 8/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.5944e-04 - val_loss: 2.4946e-04\n",
      "Epoch 9/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.4471e-04 - val_loss: 2.5066e-04\n",
      "Epoch 10/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.3838e-04 - val_loss: 2.3932e-04\n",
      "Epoch 11/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.3463e-04 - val_loss: 2.3304e-04\n",
      "Epoch 12/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.3219e-04 - val_loss: 2.3355e-04\n",
      "Epoch 13/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.3037e-04 - val_loss: 2.2475e-04\n",
      "Epoch 14/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.2891e-04 - val_loss: 2.2080e-04\n",
      "Epoch 15/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2767e-04 - val_loss: 2.1905e-04\n",
      "Epoch 16/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.2666e-04 - val_loss: 2.1515e-04\n",
      "Epoch 17/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2583e-04 - val_loss: 2.1404e-04\n",
      "Epoch 18/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2514e-04 - val_loss: 2.1563e-04\n",
      "Epoch 19/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2454e-04 - val_loss: 2.1688e-04\n",
      "Epoch 20/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2402e-04 - val_loss: 2.0594e-04\n",
      "Epoch 21/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2359e-04 - val_loss: 2.0886e-04\n",
      "Epoch 22/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2318e-04 - val_loss: 2.0768e-04\n",
      "Epoch 23/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2285e-04 - val_loss: 2.0649e-04\n",
      "Epoch 24/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2248e-04 - val_loss: 2.0423e-04\n",
      "Epoch 25/50\n",
      "899820/899820 [==============================] - 5s 6us/step - loss: 1.2221e-04 - val_loss: 2.0468e-04\n",
      "Epoch 26/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2191e-04 - val_loss: 2.0413e-04\n",
      "Epoch 27/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2161e-04 - val_loss: 2.0042e-04\n",
      "Epoch 28/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2136e-04 - val_loss: 2.0400e-04\n",
      "Epoch 29/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2113e-04 - val_loss: 2.0385e-04\n",
      "Epoch 30/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2089e-04 - val_loss: 2.0283e-04\n",
      "Epoch 31/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2063e-04 - val_loss: 1.9834e-04\n",
      "Epoch 32/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.2049e-04 - val_loss: 2.0244e-04\n",
      "Epoch 33/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.2029e-04 - val_loss: 2.0339e-04\n",
      "Epoch 34/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.2007e-04 - val_loss: 2.0234e-04\n",
      "Epoch 35/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1986e-04 - val_loss: 2.0450e-04\n",
      "Epoch 36/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1972e-04 - val_loss: 1.9826e-04\n",
      "Epoch 37/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1957e-04 - val_loss: 2.0528e-04\n",
      "Epoch 38/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1943e-04 - val_loss: 1.9790e-04\n",
      "Epoch 39/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1923e-04 - val_loss: 2.0065e-04\n",
      "Epoch 40/50\n",
      "899820/899820 [==============================] - 5s 5us/step - loss: 1.1909e-04 - val_loss: 1.9808e-04\n",
      "Epoch 41/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1892e-04 - val_loss: 2.0095e-04\n",
      "Epoch 42/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1881e-04 - val_loss: 2.0014e-04\n",
      "Epoch 43/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.1861e-04 - val_loss: 2.0175e-04\n",
      "Epoch 44/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1850e-04 - val_loss: 1.9868e-04\n",
      "Epoch 45/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1836e-04 - val_loss: 2.0068e-04\n",
      "Epoch 46/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1830e-04 - val_loss: 1.9890e-04\n",
      "Epoch 47/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1810e-04 - val_loss: 1.9586e-04\n",
      "Epoch 48/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1801e-04 - val_loss: 2.0059e-04\n",
      "Epoch 49/50\n",
      "899820/899820 [==============================] - 4s 5us/step - loss: 1.1786e-04 - val_loss: 1.9624e-04\n",
      "Epoch 50/50\n",
      "899820/899820 [==============================] - 4s 4us/step - loss: 1.1775e-04 - val_loss: 2.0098e-04\n"
     ]
    }
   ],
   "source": [
    "# Train model for 100 epochs, batch size of 10: \n",
    "NUM_EPOCHS=50\n",
    "BATCH_SIZE=1028\n",
    "\n",
    "history=model.fit(X_train, X_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  validation_split=0.1,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mse'] = np.mean(np.abs(X_pred-X_train), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_test = model.predict(X_test)\n",
    "scored_test = pd.DataFrame()\n",
    "scored_test['Loss_mse'] = np.mean(np.abs(X_pred_test-X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(train_time, scored['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Time (s)')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAACeCAYAAABD0NHYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQ4UlEQVR4nO3de6wmZ10H8O+P1kpSqRS6hbpbaYFKbSKFuhQQjUUQaSUsRog1DW1IkwaFAipK1USNeIHEcDOCNkWDSRVJQWhsVcqlGrnZLfQCLKUrQbu22pXWQm21tvvzj3dW3i7nnH337HnPbT6f5OTMPPPMvM9Lzq8z++WZmeruAAAAADAej1jrAQAAAACwugRCAAAAACMjEAIAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDIzBUJV9eiquqKqvlRVu6rq2VX1mKq6pqpuHX4fO/StqnpHVe2uqpuq6oz5fgUAAAAADsWsM4TenuRvuvvUJKcn2ZXkkiQf7e5Tknx0WE+Ss5OcMvxclORdKzpiAAAAAA5LdffSHaqOSXJjkif2VOequiXJWd19R1WdkOTa7n5KVf3RsPznB/ab27cAAAAAYGazzBB6YpK9Sf6kqj5XVZdV1dFJHrc/5Bl+Hz/035rktqn99wxtAAAAAKwDR87Y54wkF3f3Z6rq7fnm7WELqQXavmUaUlVdlMktZTn66KO//9RTT51hKAAAAADM4vrrr/+P7t6y0LZZAqE9SfZ092eG9SsyCYT+vapOmLpl7M6p/idO7b8tye0HHrS7L01yaZJs3769d+7cOdOXAQAAAODgquqfF9t20FvGuvvfktxWVU8Zmp6X5ItJrkxywdB2QZIPDctXJjl/eNvYs5Lc4/lBAAAAAOvHLDOEkuTiJJdX1VFJvpLkFZmESe+rqguT/EuSlw19r05yTpLdSe4b+gIAAACwTswUCHX3DUm2L7DpeQv07SSvOsxxAQAAADAns7xlDAAAAIBNRCAEAAAAMDICIQAAAICREQgBAAAAjIxACAAAAGBkBEIAAAAAIyMQAgAAABgZgRAAAADAyAiEAAAAAEZGIAQAAAAwMgIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARkYgBAAAADAyAiEAAACAkREIAQAAAIyMQAgAAABgZARCAAAAACMjEAIAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDICIQAAAICRmTkQqqojqupzVfVXw/rJVfWZqrq1qv6iqo4a2r99WN89bD9pPkMHAAAAYDkOZYbQa5Psmlp/c5K3dvcpSe5OcuHQfmGSu7v7yUneOvQDAAAAYJ2YKRCqqm1JfjzJZcN6JfmRJFcMXd6T5CXD8o5hPcP25w39AQAAAFgHZp0h9LYkv5Rk37D+2CT/2d0PDut7kmwdlrcmuS1Jhu33DP0BAAAAWAcOGghV1YuS3Nnd1083L9C1Z9g2fdyLqmpnVe3cu3fvTIMFAAAA4PDNMkPoOUleXFVfTfLeTG4Ve1uSR1fVkUOfbUluH5b3JDkxSYbt35nkrgMP2t2Xdvf27t6+ZcuWw/oSAAAAAMzuoIFQd/9yd2/r7pOSnJvkY919XpKPJ3np0O2CJB8alq8c1jNs/1h3f8sMIQAAAADWxqG8ZexAb0jy81W1O5NnBL17aH93kscO7T+f5JLDGyIAAAAAK+nIg3f5pu6+Nsm1w/JXkpy5QJ//TvKyFRgbAAAAAHNwODOEAAAAANiABEIAAAAAIyMQAgAAABgZgRAAAADAyAiEAAAAAEZGIAQAAAAwMgIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARkYgBAAAADAyAiEAAACAkREIAQAAAIyMQAgAAABgZARCAAAAACMjEAIAAAAYGYEQAAAAwMgIhAAAAABGRiAEAAAAMDICIQAAAICREQgBAAAAjIxACAAAAGBkBEIAAAAAIyMQAgAAABgZgRAAAADAyBw0EKqqE6vq41W1q6q+UFWvHdofU1XXVNWtw+9jh/aqqndU1e6quqmqzpj3lwAAAABgdrPMEHowyS909/cmeVaSV1XVaUkuSfLR7j4lyUeH9SQ5O8kpw89FSd614qMGAAAAYNkOGgh19x3d/dlh+RtJdiXZmmRHkvcM3d6T5CXD8o4kf9oTn07y6Ko6YcVHDgAAAMCyHNIzhKrqpCRPT/KZJI/r7juSSWiU5Pih29Ykt03ttmdoAwAAAGAdmDkQqqrvSPL+JK/r7q8v1XWBtl7geBdV1c6q2rl3795ZhwEAAADAYZopEKqqb8skDLq8uz8wNP/7/lvBht93Du17kpw4tfu2JLcfeMzuvrS7t3f39i1btix3/AAAAAAcolneMlZJ3p1kV3e/ZWrTlUkuGJYvSPKhqfbzh7eNPSvJPftvLQMAAABg7R05Q5/nJHl5kpur6oah7VeSvCnJ+6rqwiT/kuRlw7ark5yTZHeS+5K8YkVHDAAAAMBhOWgg1N3/kIWfC5Qkz1ugfyd51WGOCwAAAIA5OaS3jAEAAACw8QmEAAAAAEZGIAQAAAAwMgIhAAAAgJERCAEAAACMjEAIAAAAYGQEQgAAAAAjIxACAAAAGBmBEAAAAMDICIQAAAAARkYgtMHt/Opdue+BB9d6GAAAAMAGIhDawP5p77156R9+Kr9z9a61HgoAAACwgQiENrDP/+s9SZKv3fvAGo8EAAAA2EgEQhvYfQ88lCQ55pHftsYjAQAAADYSgdAmULXWIwAAAAA2EoHQBta91iMAAAAANiKBEAAAAMDICIQAAAAARkYgtAl4hhAAAABwKARCG1jHQ4QAAACAQycQ2sD2yYMAAACAZRAIbWDtNWMAAADAMgiENrCH/n+KkIcIAQAAALMTCG1gbhkDAAAAlkMgtIHtkwgBAAAAyyAQ2sD2eYYQAAAAsAwCoQ1sfxzk4dIAAADAoZhLIFRVL6yqW6pqd1VdMo/PINmfA5kpBAAAAByKFQ+EquqIJH+Q5OwkpyX56ao6baU/h6SHOULyIAAAAOBQHDmHY56ZZHd3fyVJquq9SXYk+eIcPmtT6O7s68nvzmTGz/Tsn+48vL0nYdD9Dzw02X+tBg4AAABsSPMIhLYmuW1qfU+SZ87hc9ad7b/1kdz3wIMPa5sOdHqhcGcFXHH9nlx10x2pWpnjHcxyP+Zwv+4qfb11Z/K3c/jHmdffx3qeoTb9nQ/n66+XrzjWGtgo1vrvZLoWV+t8sBB/pyy3Fpb621nr+lrv1B3Ayvv4L56V4x/1yLUexlzNIxBa6Jz0LefxqrooyUXD6r1VdcscxrLajkvyH2s9CNgA1ArMRq3AbNQKzEatwGyOe9wbN02tPGGxDfMIhPYkOXFqfVuS2w/s1N2XJrl0Dp+/ZqpqZ3dvX+txwHqnVmA2agVmo1ZgNmoFZjOWWpnHW8auS3JKVZ1cVUclOTfJlXP4HAAAAACWYcVnCHX3g1X16iR/m+SIJH/c3V9Y6c8BAAAAYHnmcctYuvvqJFfP49jr3Ka6BQ7mSK3AbNQKzEatwGzUCsxmFLVSvZ5fEQQAAADAipvHM4QAAAAAWMcEQstUVW+sqpuq6oaq+nBVfdfQflZV3TO031BVvza1zwur6paq2l1Vl6zd6GH1LFYrU9ufUVUPVdVLp9ouqKpbh58LVn/UsPqWOK/smGrfWVU/OLWPWmF0lqiV84b2m6rqk1V1+tQ+rsEYnSVq5dSq+lRV/U9Vvf6AfdQKo7NErVRVvWOoh5uq6oypfTbFNZhbxpapqo7p7q8Py69Jclp3v7Kqzkry+u5+0QH9j0jy5SQ/mmRPJm9j++nu/uLqjhxW12K1MqwfkeSaJP+dyQPor6iqxyTZmWR7kk5yfZLv7+671+QLwCpZ4rzyHUn+q7u7qp6a5H3dfapaYayWqJUfSLKru++uqrOT/EZ3P9M1GGO1RK0cn+QJSV6S5O7u/r2hj1phlJaolXOSXJzknCTPTPL24byyaa7BzBBapv1/MIOjM/lDWMqZSXZ391e6+4Ek702yY17jg/XiILVycZL3J7lzqu3HklzT3XcN/1G9JskL5z5QWGOL1Up339vf/H9vpmtIrTBKS9TKJ6cuxj+dZNuw7BqMUVqiVu7s7uuS/O8Bu6gVRmmJf6/sSPKnPfHpJI+uqhOyia7B5vKWsbGoqt9Ocn6Se5I8d2rTs6vqxiS3ZzJb6AtJtia5barPnkxSRtj0FqqVqtqa5CeS/EiSZ0x1X6hWtq7OSGFtLXZeqaqfSPK7SY5P8uNDs1phtJa4BtvvwiR/PSy7BmO0ZqiVaWqF0VqkVha71to012BmCC2hqj5SVZ9f4GdHknT3r3b3iUkuT/LqYbfPJnlCd5+e5PeTfHD/4Rb4CPfrsSkss1beluQN3f3QgYdb4CPUCpvCMmsl3f2X3X1qJtP737j/cAt8hFphU1hurQz7PjeTQOgN+5sW+Ai1wqZwOLWy0OEWaFMrbArLrJXFamLT1IoZQkvo7ufP2PXPklyV5Nenp5t199VV9c6qOi6T1PDEqX22ZTKDCDa85dRKJvfcvreqkuS4JOdU1YOZ1MpZU/tsS3LtSo0V1tIya2V6/7+vqidNnVfOmtqsVtg0llsrw3O2Lktydnd/bejjGoxN63DPKwdQK2xay6yVxWpi01yDmSG0TFV1ytTqi5N8aWh/fA3/wq2qMzP53/hrmTyU7ZSqOrmqjkpybpIrV3fUsPoWq5XuPrm7T+ruk5JckeRnu/uDSf42yQuq6tiqOjbJC4Y22NSWOK88eeq8ckaSozI5r6gVRmmJWvnuJB9I8vLu/vJUH9dgjNJitbIEtcIoLVErVyY5f3jb2LOS3NPdd2QTXYOZIbR8b6qqpyTZl+Sfk7xyaH9pkp8ZZjrcn+Tc4WGgD1bVqzP5QzkikzcqfWENxg2rbbFaWVB331VVb8zkoiRJfrO775rzGGE9WKxWfjKTi5H/zeS88lPDeUWtMFaL1cqvJXlskncOGeqD3b29u12DMVYL1kpVPT6TNyQdk2RfVb0uk7cqfV2tMFKLnVeuzuQNY7uT3JfkFcnm+veK184DAAAAjIxbxgAAAABGRiAEAAAAMDICIQAAAICREQgBAAAAjIxACAAAAGBkBEIAwKZWVY+tqhuGn3+rqn+dWv/knD7z6VV12RLbt1TV38zjswEAZnHkWg8AAGCeuvtrSZ6WJFX1G0nu7e7fm/PH/kqS31piTHur6o6qek53f2LOYwEA+BZmCAEAo1VV9w6/z6qqv6uq91XVl6vqTVV1XlX9Y1XdXFVPGvptqar3V9V1w89zFjjmo5I8tbtvHNZ/eGpG0ueG7UnywSTnrdJXBQB4GIEQAMDE6Ulem+T7krw8yfd095lJLkty8dDn7Une2t3PSPKTw7YDbU/y+an11yd5VXc/LckPJbl/aN85rAMArDq3jAEATFzX3XckSVX9U5IPD+03J3nusPz8JKdV1f59jqmqR3X3N6aOc0KSvVPrn0jylqq6PMkHunvP0H5nku9a+a8BAHBwAiEAgIn/mVreN7W+L9+8ZnpEkmd39/1Z3P1JHrl/pbvfVFVXJTknyaer6vnd/aWhz1LHAQCYG7eMAQDM7sNJXr1/paqetkCfXUmePNXnSd19c3e/OZPbxE4dNn1PHn5rGQDAqhEIAQDM7jVJtlfVTVX1xSSvPLDDMPvnO6ceHv26qvp8Vd2YyYygvx7an5vkqtUYNADAgaq713oMAACbSlX9XJJvdPdCD53e3+fvk+zo7rtXb2QAABNmCAEArLx35eHPJHqYqtqS5C3CIABgrZghBAAAADAyZggBAAAAjIxACAAAAGBkBEIAAAAAIyMQAgAAABgZgRAAAADAyAiEAAAAAEbm/wAgCU+eajbEXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "plt.plot(test_time, scored_test['Loss_mse'])\n",
    "plt.ylim([0, 600])\n",
    "#plt.xlim([-10,-8])\n",
    "plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
